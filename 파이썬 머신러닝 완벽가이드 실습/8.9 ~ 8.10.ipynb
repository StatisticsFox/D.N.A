{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                           document  label\n",
       "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('ratings_train.txt', sep='\\t')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75173\n",
       "1    74827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "train_df = train_df.fillna(' ')\n",
    "# 정규 표현식을 이용하여 숫자를 공백으로 변경(정규 표현식으로 \\d 는 숫자를 의미함.) \n",
    "train_df['document'] = train_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n",
    "\n",
    "# 테스트 데이터 셋을 로딩하고 동일하게 Null 및 숫자를 공백으로 변환\n",
    "test_df = pd.read_csv('ratings_test.txt', sep='\\t')\n",
    "test_df = test_df.fillna(' ')\n",
    "test_df['document'] = test_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n",
    "\n",
    "# id 칼럼 삭제 수행\n",
    "train_df.drop('id', axis=1, inplace=True) \n",
    "test_df.drop('id', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yong\\anaconda3\\envs\\pymldgrev2\\lib\\site-packages\\konlpy\\tag\\_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "def tw_tokenizer(text):\n",
    "    # 입력 인자로 들어온 text 를 형태소 단어로 토큰화 하여 list 객체 반환\n",
    "    tokens_ko = twitter.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yong\\anaconda3\\envs\\pymldgrev2\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Twitter 객체의 morphs( ) 객체를 이용한 tokenizer를 사용. ngram_range는 (1,2) \n",
    "tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf_vect.fit(train_df['document'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "{'C': 3.5} 0.8593\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 을 이용하여 감성 분석 Classification 수행. \n",
    "lg_clf = LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "# Parameter C 최적화를 위해 GridSearchCV 를 이용. \n",
    "params = { 'C': [1 ,3.5, 4.5, 5.5, 10 ] }\n",
    "grid_cv = GridSearchCV(lg_clf , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(tfidf_matrix_train , train_df['label'] )\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 정확도:  0.86172\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 학습 데이터를 적용한 TfidfVectorizer를 이용하여 테스트 데이터를 TF-IDF 값으로 Feature 변환함. \n",
    "tfidf_matrix_test = tfidf_vect.transform(test_df['document'])\n",
    "\n",
    "# classifier 는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용\n",
    "best_estimator = grid_cv.best_estimator_\n",
    "preds = best_estimator.predict(tfidf_matrix_test)\n",
    "\n",
    "print('Logistic Regression 정확도: ',accuracy_score(test_df['label'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge , LogisticRegression\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "mercari_df= pd.read_csv('mercari_train.tsv',sep='\\t')\n",
    "print(mercari_df.shape)\n",
    "mercari_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mercari_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_train_df = mercari_df['price']\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(y_train_df, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_train_df = np.log1p(y_train_df)\n",
    "sns.histplot(y_train_df, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercari_df['price'] = np.log1p(mercari_df['price'])\n",
    "mercari_df['price'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shipping 값 유형:\\n',mercari_df['shipping'].value_counts())\n",
    "print('item_condition_id 값 유형:\\n',mercari_df['item_condition_id'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_cond= mercari_df['item_description']=='No description yet'\n",
    "mercari_df[boolean_cond]['item_description'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lambda에서 호출되는 대,중,소 분할 함수 생성, 대,중,소 값을 리스트 반환\n",
    "def split_cat(category_name):\n",
    "    try:\n",
    "        return category_name.split('/')\n",
    "    except:\n",
    "        return ['Other_Null' , 'Other_Null' , 'Other_Null']\n",
    "\n",
    "# 위의 split_cat( )을 apply lambda에서 호출하여 대,중,소 컬럼을 mercari_df에 생성. \n",
    "mercari_df['cat_dae'], mercari_df['cat_jung'], mercari_df['cat_so'] = \\\n",
    "                        zip(*mercari_df['category_name'].apply(lambda x : split_cat(x)))\n",
    "\n",
    "# 대분류만 값의 유형과 건수를 살펴보고, 중분류, 소분류는 값의 유형이 많으므로 분류 갯수만 추출\n",
    "print('대분류 유형 :\\n', mercari_df['cat_dae'].value_counts())\n",
    "print('중분류 갯수 :', mercari_df['cat_jung'].nunique())\n",
    "print('소분류 갯수 :', mercari_df['cat_so'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercari_df['brand_name'] = mercari_df['brand_name'].fillna(value='Other_Null')\n",
    "mercari_df['category_name'] = mercari_df['category_name'].fillna(value='Other_Null')\n",
    "mercari_df['item_description'] = mercari_df['item_description'].fillna(value='Other_Null')\n",
    "\n",
    "# 각 컬럼별로 Null값 건수 확인. 모두 0가 나와야 합니다.\n",
    "mercari_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 인코딩과 피처 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('brand name 의 유형 건수 :', mercari_df['brand_name'].nunique())\n",
    "print('brand name sample 5건 : \\n', mercari_df['brand_name'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('name 의 종류 갯수 :', mercari_df['name'].nunique())\n",
    "print('name sample 7건 : \\n', mercari_df['name'][:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "# item_description의 평균 문자열 개수\n",
    "print('item_description 평균 문자열 개수:',mercari_df['item_description'].str.len().mean())\n",
    "\n",
    "mercari_df['item_description'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name 속성에 대한 feature vectorization 변환\n",
    "cnt_vec = CountVectorizer()\n",
    "X_name = cnt_vec.fit_transform(mercari_df.name)\n",
    "\n",
    "# item_description 에 대한 feature vectorization 변환 \n",
    "tfidf_descp = TfidfVectorizer(max_features = 50000, ngram_range= (1,3) , stop_words='english')\n",
    "X_descp = tfidf_descp.fit_transform(mercari_df['item_description'])\n",
    "\n",
    "print('name vectorization shape:',X_name.shape)\n",
    "print('item_description vectorization shape:',X_descp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# brand_name, item_condition_id, shipping 각 피처들을 희소 행렬 원-핫 인코딩 변환\n",
    "lb_brand_name= LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb_brand_name.fit_transform(mercari_df['brand_name'])\n",
    "\n",
    "lb_item_cond_id = LabelBinarizer(sparse_output=True)\n",
    "X_item_cond_id = lb_item_cond_id.fit_transform(mercari_df['item_condition_id'])\n",
    "\n",
    "lb_shipping= LabelBinarizer(sparse_output=True)\n",
    "X_shipping = lb_shipping.fit_transform(mercari_df['shipping'])\n",
    "\n",
    "# cat_dae, cat_jung, cat_so 각 피처들을 희소 행렬 원-핫 인코딩 변환\n",
    "lb_cat_dae = LabelBinarizer(sparse_output=True)\n",
    "X_cat_dae= lb_cat_dae.fit_transform(mercari_df['cat_dae'])\n",
    "\n",
    "lb_cat_jung = LabelBinarizer(sparse_output=True)\n",
    "X_cat_jung = lb_cat_jung.fit_transform(mercari_df['cat_jung'])\n",
    "\n",
    "lb_cat_so = LabelBinarizer(sparse_output=True)\n",
    "X_cat_so = lb_cat_so.fit_transform(mercari_df['cat_so'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_brand), type(X_item_cond_id), type(X_shipping))\n",
    "print('X_brand_shape:{0}, X_item_cond_id shape:{1}'.format(X_brand.shape, X_item_cond_id.shape))\n",
    "print('X_shipping shape:{0}, X_cat_dae shape:{1}'.format(X_shipping.shape, X_cat_dae.shape))\n",
    "print('X_cat_jung shape:{0}, X_cat_so shape:{1}'.format(X_cat_jung.shape, X_cat_so.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  scipy.sparse import hstack\n",
    "import gc\n",
    "\n",
    "sparse_matrix_list = (X_name, X_descp, X_brand, X_item_cond_id,\n",
    "            X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "\n",
    "# 사이파이 sparse 모듈의 hstack 함수를 이용하여 앞에서 인코딩과 Vectorization을 수행한 데이터 셋을 모두 결합. \n",
    "X_features_sparse= hstack(sparse_matrix_list).tocsr()\n",
    "print(type(X_features_sparse), X_features_sparse.shape)\n",
    "\n",
    "# 데이터 셋이 메모리를 많이 차지하므로 사용 용도가 끝났으면 바로 메모리에서 삭제. \n",
    "del X_features_sparse\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 릿지 회귀 모델 구축 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y , y_pred):\n",
    "    # underflow, overflow를 막기 위해 log가 아닌 log1p로 rmsle 계산 \n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y) - np.log1p(y_pred), 2)))\n",
    "\n",
    "def evaluate_org_price(y_test , preds): \n",
    "    \n",
    "    # 원본 데이터는 log1p로 변환되었으므로 exmpm1으로 원복 필요. \n",
    "    preds_exmpm = np.expm1(preds)\n",
    "    y_test_exmpm = np.expm1(y_test)\n",
    "    \n",
    "    # rmsle로 RMSLE 값 추출\n",
    "    rmsle_result = rmsle(y_test_exmpm, preds_exmpm)\n",
    "    return rmsle_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "from  scipy.sparse import hstack\n",
    "\n",
    "def model_train_predict(model,matrix_list):\n",
    "    # scipy.sparse 모듈의 hstack 을 이용하여 sparse matrix 결합\n",
    "    X= hstack(matrix_list).tocsr()     \n",
    "    \n",
    "    X_train, X_test, y_train, y_test=train_test_split(X, mercari_df['price'], \n",
    "                                                      test_size=0.2, random_state=156)\n",
    "    \n",
    "    # 모델 학습 및 예측\n",
    "    model.fit(X_train , y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    del X , X_train , X_test , y_train \n",
    "    gc.collect()\n",
    "    \n",
    "    return preds , y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Ridge(solver = \"lsqr\", fit_intercept=False)\n",
    "\n",
    "sparse_matrix_list = (X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "linear_preds , y_test = model_train_predict(model=linear_model ,matrix_list=sparse_matrix_list)\n",
    "print('Item Description을 제외했을 때 rmsle 값:', evaluate_org_price(y_test , linear_preds))\n",
    "\n",
    "sparse_matrix_list = (X_descp, X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "linear_preds , y_test = model_train_predict(model=linear_model , matrix_list=sparse_matrix_list)\n",
    "print('Item Description을 포함한 rmsle 값:',  evaluate_org_price(y_test ,linear_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM 회귀 모델 구축과 앙상블을 이용한 최종 예측 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "sparse_matrix_list = (X_descp, X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "\n",
    "lgbm_model = LGBMRegressor(n_estimators=200, learning_rate=0.5, num_leaves=125, random_state=156)\n",
    "lgbm_preds , y_test = model_train_predict(model = lgbm_model , matrix_list=sparse_matrix_list)\n",
    "print('LightGBM rmsle 값:',  evaluate_org_price(y_test , lgbm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lgbm_preds * 0.45 + linear_preds * 0.55\n",
    "print('LightGBM과 Ridge를 ensemble한 최종 rmsle 값:',  evaluate_org_price(y_test , preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
